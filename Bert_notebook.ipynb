{ "cells": [ { "cell_type": "markdown", "id": "ffef", "metadata": {}, "source": [ "# BERT Fine-tuning for Sentiment Analysis\n", "\n", "This notebook demonstrates how to fine-tune a pre-trained BERT model for sentiment analysis using the IMDB movie reviews dataset. We'll compare the performance of a traditional machine learning baseline (TF-IDF + Logistic Regression) with a fine-tuned BERT model.\n", "\n", "## **Project Goals:**\n", "- Load and explore the IMDB dataset\n", "- Establish a baseline using traditional ML methods\n", "- Fine-tune BERT for binary sentiment classification\n", "- Compare performance between baseline and BERT models\n", "\n", "## **Expected Outcomes:**\n", "- **Baseline Model**: ~-% accuracy\n", "- **Fine-tuned BERT**: ~-% accuracy\n", "- **Learning**: Understanding transformer-based models vs traditional approaches\n", "\n", "---" ] }, { "cell_type": "markdown", "id": "ccb", "metadata": {}, "source": [ "## Step : Dataset Loading and Exploration\n", "\n", "First, we'll load the famous IMDB movie reviews dataset which contains , reviews (k for training, k for testing) labeled as positive or negative sentiment." ] }, { "cell_type": "code", "execution_count": null, "id": "af", "metadata": {}, "outputs": [ { "name": "stderr", "output_type": "stream", "text": [ "c:\\Users\\Prahalad M\\Desktop\\resume_projects\\BERT-finetuning\\venv\\Lib\\site-packages\\tqdm\\auto.py:: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n", " from .autonotebook import tqdm as notebook_tqdm\n" ] } ], "source": [ "# Load the IMDB dataset using Hugging Face datasets library\n", "# This dataset contains k training and k test movie reviews\n", "from datasets import load_dataset\n", "\n", "# Download and load the dataset (may take a few minutes on first run)\n", "dataset = load_dataset(\"imdb\") " ] }, { "cell_type": "code", "execution_count": null, "id": "ccbd", "metadata": {}, "outputs": [ { "name": "stdout", "output_type": "stream", "text": [ "DatasetDict({\n", " train: Dataset({\n", " features: ['text', 'label'],\n", " num_rows: \n", " })\n", " test: Dataset({\n", " features: ['text', 'label'],\n", " num_rows: \n", " })\n", " unsupervised: Dataset({\n", " features: ['text', 'label'],\n", " num_rows: \n", " })\n", "})\n" ] } ], "source": [ "# Explore the structure of our dataset\n", "# This shows us the training and test splits with their sizes\n", "print(dataset)" ] }, { "cell_type": "code", "execution_count": null, "id": "ab", "metadata": {}, "outputs": [ { "name": "stdout", "output_type": "stream", "text": [ "{'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in . I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.', 'label': }\n" ] } ], "source": [ "# Look at a sample review to understand the data structure\n", "# Each sample contains 'text' (review content) and 'label' (=negative, =positive)\n", "print(dataset['train'][])" ] }, { "cell_type": "code", "execution_count": null, "id": "befe", "metadata": {}, "outputs": [ { "name": "stdout", "output_type": "stream", "text": [ "postive reviews: \n", "negative reviews: \n" ] } ], "source": [ "# Check the class balance in our training data\n", "# Labels: = negative sentiment, = positive sentiment\n", "train_labels = dataset['train']['label']\n", "print(f\"Positive reviews: {sum(train_labels)}\")\n", "print(f\"Negative reviews: {len(train_labels) - sum(train_labels)}\")\n", "print(f\"Dataset is {'balanced' if sum(train_labels) == len(train_labels) - sum(train_labels) else 'imbalanced'}\")" ] }, { "cell_type": "markdown", "id": "af", "metadata": {}, "source": [ "## Step : Baseline Model (Traditional ML Approach)\n", "\n", "Before jumping into BERT, let's establish a baseline using traditional machine learning:\n", "- **TF-IDF**: Convert text to numerical features\n", "- **Logistic Regression**: Simple but effective classifier\n", "\n", "This helps us understand how much improvement BERT provides over classical methods." ] }, { "cell_type": "code", "execution_count": null, "id": "ac", "metadata": {}, "outputs": [ { "name": "stdout", "output_type": "stream", "text": [ "Training on reviews\n", "Testing on reviews\n" ] } ], "source": [ "# Import libraries for our baseline machine learning model\n", "from sklearn.feature_extraction.text import TfidfVectorizer\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.metrics import accuracy_score, classification_report\n", "\n", "# Prepare our text data for traditional ML processing\n", "train_texts = dataset['train']['text']\n", "train_labels = dataset['train']['label'] \n", "test_labels = dataset['test']['label']\n", "test_texts = dataset['test']['text']\n", "\n", "# Show dataset size information\n", "print(f\"Training on {len(train_texts):,} reviews\")\n", "print(f\"Testing on {len(test_texts):,} reviews\")" ] }, { "cell_type": "code", "execution_count": null, "id": "cc", "metadata": {}, "outputs": [ { "name": "stdout", "output_type": "stream", "text": [ "Converting text to TF-IDF features\n", "TF-IDF shape: (, )\n", "Each review is represented by a vector of length numbers\n" ] } ], "source": [ "# Convert text to numerical features using TF-IDF\n", "# TF-IDF (Term Frequency-Inverse Document Frequency) measures word importance\n", "# - Higher values = words that appear frequently in this doc but rarely in others\n", "# - ngram_range=(,) = consider both single words and word pairs\n", "print(\"Converting text to TF-IDF features...\")\n", "vectorizer = TfidfVectorizer(\n", " max_features=, # Keep only the most important features\n", " ngram_range=(,) # Use single words and word pairs (bigrams)\n", ")\n", "\n", "# Fit vectorizer on training data and transform both train and test sets\n", "X_train = vectorizer.fit_transform(train_texts)\n", "X_test = vectorizer.transform(test_texts)\n", "\n", "print(f\" TF-IDF transformation complete!\")\n", "print(f\"Feature matrix shape: {X_train.shape}\")\n", "print(f\"Each review is now represented by {X_train.shape[]:,} numerical features\")" ] }, { "cell_type": "code", "execution_count": null, "id": "bfb", "metadata": {}, "outputs": [ { "name": "stdout", "output_type": "stream", "text": [ "Training Logistic Regression model\n", "Making predictions on test set\n", "\n", "==================================================\n", "BASELINE MODEL PERFORMANCE\n", "==================================================\n", "Accuracy: . (.%)\n", "\n", "Detailed Classification Report:\n", " precision recall f-score support\n", "\n", " Negative . . . \n", " Positive . . . \n", "\n", " accuracy . \n", " macro avg . . . \n", "weighted avg . . . \n", "\n" ] } ], "source": [ "# Train our baseline logistic regression model\n", "print(\" Training Logistic Regression baseline model...\")\n", "baseline_model = LogisticRegression(max_iter=)\n", "baseline_model.fit(X_train, train_labels)\n", "\n", "# Make predictions on the test set\n", "print(\" Making predictions on test set...\")\n", "predictions = baseline_model.predict(X_test)\n", "\n", "# Evaluate model performance\n", "accuracy = accuracy_score(test_labels, predictions)\n", "print(f\"\\n{'='*}\")\n", "print(f\" BASELINE MODEL PERFORMANCE\")\n", "print(f\"{'='*}\")\n", "print(f\"Accuracy: {accuracy:.f} ({accuracy*:.f}%)\")\n", "print(f\"\\n Detailed Classification Report:\")\n", "print(classification_report(test_labels, predictions, target_names=['Negative', 'Positive']))\n", "print(f\"{'='*}\")\n", "print(f\" This baseline gives us a target to beat with BERT!\")" ] }, { "cell_type": "markdown", "id": "ae", "metadata": {}, "source": [ "## Step : BERT Model Setup\n", "\n", "Now let's implement the star of our show - BERT! \n", "\n", "**What is BERT?**\n", "- **B**idirectional **E**ncoder **R**epresentations from **T**ransformers\n", "- Pre-trained on massive text corpora (Wikipedia + BookCorpus)\n", "- Understands context from both left AND right sides of words\n", "- State-of-the-art performance on many NLP tasks\n", "\n", "**Why BERT is powerful:**\n", "- Captures complex language patterns and relationships\n", "- Pre-trained knowledge can be fine-tuned for specific tasks\n", "- Bidirectional context understanding (unlike traditional left-to-right models)" ] }, { "cell_type": "code", "execution_count": null, "id": "cbdc", "metadata": {}, "outputs": [ { "name": "stdout", "output_type": "stream", "text": [ "Loading BERT tokenizer...\n", "Loading BERT model...\n" ] }, { "name": "stderr", "output_type": "stream", "text": [ "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n", "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n" ] }, { "name": "stdout", "output_type": "stream", "text": [ " Model and tokenizer loaded!\n", "Model has ,, parameters\n" ] } ], "source": [ "# Load pre-trained BERT components from Hugging Face\n", "from transformers import BertTokenizer, BertForSequenceClassification\n", "\n", "print(\" Loading BERT tokenizer...\")\n", "# The tokenizer converts text into tokens that BERT can understand\n", "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n", "\n", "print(\" Loading pre-trained BERT model...\")\n", "# Load BERT with a classification head for binary sentiment analysis\n", "model = BertForSequenceClassification.from_pretrained(\n", " 'bert-base-uncased', # -layer, -hidden, -heads, M parameters\n", " num_labels= # Binary classification: positive/negative\n", ")\n", "\n", "print(\" BERT model and tokenizer loaded successfully!\")\n", "print(f\" Model size: {model.num_parameters():,} parameters\")\n", "\n", "# **What's happening under the hood:**\n", "#\n", "# **bert-base-uncased Model Architecture:**\n", "# - transformer layers (compared to in bert-large)\n", "# - hidden dimensions\n", "# - attention heads per layer\n", "# - ~ million trainable parameters\n", "# - \"uncased\" = not case-sensitive (converts \"Hello\" → \"hello\")\n", "#\n", "# **BertTokenizer Functions:**\n", "# - Vocabulary: , unique tokens\n", "# - Subword tokenization: \"unbelievable\" → [\"un\", \"##believe\", \"##able\"]\n", "# - Special tokens: [CLS] (start), [SEP] (separator), [PAD] (padding)\n", "# - Handles out-of-vocabulary words gracefully\n", "#\n", "# **BertForSequenceClassification:**\n", "# - Pre-trained BERT encoder + classification head\n", "# - Classification head: dropout + linear layer ( → outputs)\n", "# - Only the classification head is randomly initialized\n", "# - BERT weights start from pre-trained values\n", "#\n", "# 💾 **First-time setup:**\n", "# - Downloads ~MB of model weights\n", "# - Caches locally for future use\n", "# - Takes - minutes depending on internet speed" ] }, { "cell_type": "code", "execution_count": null, "id": "caff", "metadata": {}, "outputs": [ { "name": "stdout", "output_type": "stream", "text": [ "Tokenizing training data...\n", "Tokenizing test data...\n", " Tokenization complete!\n", "Training shape: torch.Size([, ])\n", "Test shape: torch.Size([, ])\n" ] } ], "source": [ "# Tokenize our text data for BERT processing\n", "# BERT requires specific input format with special tokens and padding\n", "\n", "print(\" Tokenizing training data...\")\n", "train_encodings = tokenizer(\n", " list(train_texts),\n", " truncation=True, # Cut off reviews longer than max_length\n", " padding=True, # Pad shorter reviews to uniform length\n", " max_length=, # Maximum sequence length (balance between speed and content)\n", " return_tensors='pt' # Return PyTorch tensors\n", ")\n", "\n", "print(\" Tokenizing test data...\")\n", "test_encodings = tokenizer(\n", " list(test_texts),\n", " truncation=True,\n", " padding=True,\n", " max_length=,\n", " return_tensors='pt'\n", ")\n", "\n", "print(\" Tokenization complete!\")\n", "print(f\" Training data shape: {train_encodings['input_ids'].shape}\")\n", "print(f\" Test data shape: {test_encodings['input_ids'].shape}\")\n", "print(f\"\\n What each dimension means:\")\n", "print(f\" • First dimension ({train_encodings['input_ids'].shape[]:,}): Number of reviews\")\n", "print(f\" • Second dimension ({train_encodings['input_ids'].shape[]}): Sequence length (tokens per review)\")\n", "\n", "# **Understanding the tokenization process:**\n", "#\n", "# Input: \"This movie is great!\"\n", "# ↓\n", "# Tokens: [\"[CLS]\", \"this\", \"movie\", \"is\", \"great\", \"!\", \"[SEP]\", \"[PAD]\", \"[PAD]\", ...]\n", "# ↓\n", "# Token IDs: [, , , , , , , , , ...]\n", "# ↓ \n", "# Attention Mask: [, , , , , , , , , ...] (=real token, =padding)" ] }, { "cell_type": "code", "execution_count": null, "id": "ebd", "metadata": {}, "outputs": [ { "name": "stdout", "output_type": "stream", "text": [ " Datasets created!\n", "Training dataset size: \n", "Test dataset size: \n", "\n", "Sample data structure:\n", " input_ids shape: torch.Size([])\n", " attention_mask shape: torch.Size([])\n", " label: \n" ] } ], "source": [ "# Create custom PyTorch Dataset classes for efficient data loading\n", "import torch\n", "from torch.utils.data import Dataset, DataLoader\n", "\n", "class SentimentDataset(Dataset):\n", " \"\"\"\n", " Custom Dataset class that packages our tokenized text with labels\n", " for efficient batch processing during training\n", " \"\"\"\n", " def __init__(self, encodings, labels):\n", " self.encodings = encodings\n", " self.labels = labels\n", " \n", " def __len__(self):\n", " \"\"\"Return the total number of samples in the dataset\"\"\"\n", " return len(self.labels)\n", " \n", " def __getitem__(self, idx):\n", " \"\"\"\n", " Get a single sample from the dataset\n", " Returns: dictionary with input_ids, attention_mask, and labels\n", " \"\"\"\n", " item = {key: val[idx] for key, val in self.encodings.items()}\n", " item['labels'] = self.labels[idx]\n", " return item\n", "\n", "# Create dataset objects for training and testing\n", "print(\" Creating PyTorch datasets...\")\n", "train_dataset = SentimentDataset(train_encodings, train_labels)\n", "test_dataset = SentimentDataset(test_encodings, test_labels)\n", "\n", "print(\" Dataset objects created successfully!\")\n", "print(f\" Training dataset size: {len(train_dataset):,} reviews\")\n", "print(f\" Test dataset size: {len(test_dataset):,} reviews\")\n", "\n", "# Inspect a sample to understand the data structure\n", "sample = train_dataset[]\n", "print(f\"\\n Sample data structure:\")\n", "print(f\" • input_ids shape: {sample['input_ids'].shape} (tokenized text)\")\n", "print(f\" • attention_mask shape: {sample['attention_mask'].shape} (padding mask)\")\n", "print(f\" • label: {sample['labels']} ({'positive' if sample['labels'] == else 'negative'} sentiment)\")\n", "\n", "# **Why we need custom Dataset classes:**\n", "#\n", "# **Efficient batch processing**: PyTorch can automatically batch our data\n", "# **Memory management**: Load data on-demand rather than keeping everything in memory\n", "# **Standardized interface**: Works seamlessly with PyTorch DataLoaders\n", "# **Flexibility**: Easy to add data augmentation or preprocessing later" ] }, { "cell_type": "code", "execution_count": null, "id": "ea", "metadata": {}, "outputs": [ { "name": "stdout", "output_type": "stream", "text": [ "DataLoaders created!\n", "Training batches per epoch: \n", "Test batches: \n", "Batch size: reviews\n", "\n", "Each epoch will process batches\n" ] } ], "source": [ "# Create DataLoaders for efficient batch processing during training\n", "from torch.utils.data import DataLoader\n", "\n", "# Set up data loaders with appropriate batch sizes\n", "train_loader = DataLoader(\n", " train_dataset, \n", " batch_size=, # Process reviews at once (balance memory vs speed)\n", " shuffle=True # Shuffle training data for better learning\n", ")\n", "\n", "test_loader = DataLoader(\n", " test_dataset, \n", " batch_size=, # Same batch size for consistency\n", " shuffle=False # No need to shuffle test data\n", ")\n", "\n", "print(' DataLoaders created successfully!')\n", "print(f\" Training batches per epoch: {len(train_loader):,}\")\n", "print(f\" Test batches: {len(test_loader):,}\")\n", "print(f\" Batch size: reviews per batch\")\n", "print(f\"\\n Training process:\")\n", "print(f\" • Each epoch processes {len(train_loader):,} batches\")\n", "print(f\" • Total training samples per epoch: {len(train_loader) * :,}\")\n", "print(f\" • Estimated time per epoch: ~- minutes (depending on GPU)\")\n", "\n", "# **DataLoader benefits:**\n", "#\n", "# **Batch processing**: Train on multiple samples simultaneously\n", "# **Memory efficiency**: Load batches on-demand, not entire dataset\n", "# **Automatic shuffling**: Prevents model from memorizing data order\n", "# **Parallel loading**: Can use multiple CPU cores for data loading\n", "# **Consistent interface**: Standard PyTorch training loop compatibility" ] }, { "cell_type": "code", "execution_count": null, "id": "eead", "metadata": {}, "outputs": [], "source": [ "# PROJECT PROGRESS TRACKER \n", "# \n", "# [ Setup] → [ Data Loading] → [ Baseline Model] → [ BERT Preparation] → [ TRAINING] ← YOU ARE HERE → [Evaluation] → [Results]\n", "#\n", "# Ready to fine-tune BERT! All preprocessing complete." ] }, { "cell_type": "markdown", "id": "c", "metadata": {}, "source": [ "## Step : Training Configuration\n", "\n", "Before we start training, we need to set up our training environment and hyperparameters. This includes:\n", "- **Device selection** (GPU vs CPU)\n", "- **Optimizer configuration** (how the model learns)\n", "- **Learning rate scheduling** (adjusts learning speed during training)" ] }, { "cell_type": "code", "execution_count": null, "id": "fd", "metadata": {}, "outputs": [ { "name": "stdout", "output_type": "stream", "text": [ "Using device: cuda\n", "Model moved to device!\n" ] } ], "source": [ "# Configure the training device (GPU vs CPU)\n", "import torch \n", "\n", "# Automatically detect and use GPU if available, otherwise fall back to CPU\n", "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n", "print(f\" Using device: {device}\")\n", "\n", "if torch.cuda.is_available():\n", " print(f\" GPU: {torch.cuda.get_device_name()}\")\n", " print(f\" Memory: {torch.cuda.get_device_properties().total_memory // **} GB\")\n", "else:\n", " print(\" No GPU detected - training will be slower on CPU\")\n", "\n", "# Move our model to the selected device (GPU/CPU)\n", "model = model.to(device)\n", "print(f\" Model moved to {device}!\")\n", "\n", "# **GPU vs CPU Performance:**\n", "#\n", "# **With GPU (CUDA)**:\n", "# • Training time: ~- minutes for epochs\n", "# • Memory usage: ~-GB GPU memory\n", "# • Batch size: (or higher with more memory)\n", "#\n", "# ⏳ **With CPU only**:\n", "# • Training time: ~- hours for epochs\n", "# • Memory usage: ~-GB RAM\n", "# • Batch size: Limited by available RAM" ] }, { "cell_type": "code", "execution_count": null, "id": "daaa", "metadata": {}, "outputs": [ { "name": "stdout", "output_type": "stream", "text": [ " Optimizer configured!\n", "Learning rate: e-\n", "Total training steps: \n", "Epochs: \n", "Steps per epoch: \n" ] } ], "source": [ "# Configure optimizer and learning rate scheduler\n", "from transformers import get_linear_schedule_with_warmup\n", "from torch.optim import AdamW\n", "\n", "# Set up AdamW optimizer with weight decay (prevents overfitting)\n", "optimizer = AdamW(\n", " model.parameters(), \n", " lr=e-, # Learning rate: small value for fine-tuning\n", " weight_decay=. # L regularization to prevent overfitting\n", ")\n", "\n", "# Training configuration\n", "epochs = # Number of complete passes through the dataset\n", "total_steps = len(train_loader) * epochs\n", "\n", "# Learning rate scheduler (starts low, warms up, then decreases)\n", "scheduler = get_linear_schedule_with_warmup(\n", " optimizer,\n", " num_warmup_steps=, # No warmup (could use - for very large datasets)\n", " num_training_steps=total_steps\n", ")\n", "\n", "print(\" Training configuration complete!\")\n", "print(f\" Training hyperparameters:\")\n", "print(f\" • Learning rate: e- (optimized for BERT fine-tuning)\")\n", "print(f\" • Weight decay: . (regularization)\")\n", "print(f\" • Epochs: {epochs}\")\n", "print(f\" • Total training steps: {total_steps:,}\")\n", "print(f\" • Steps per epoch: {len(train_loader):,}\")\n", "\n", "# **Why these hyperparameters?**\n", "#\n", "# **Learning Rate (e-)**:\n", "# • BERT is pre-trained, so we need small updates\n", "# • Too high → catastrophic forgetting of pre-trained knowledge\n", "# • Too low → very slow learning or poor convergence\n", "# • e- is the sweet spot found by research\n", "#\n", "# ⚖ **Weight Decay (.)**:\n", "# • Prevents overfitting by penalizing large weights\n", "# • Standard value for transformer fine-tuning\n", "#\n", "# **Linear Decay Schedule**:\n", "# • Learning rate decreases linearly over time\n", "# • Helps model converge to optimal solution\n", "# • Alternative: cosine decay or constant rate" ] }, { "cell_type": "markdown", "id": "eeefd", "metadata": {}, "source": [ "## Step : Training Functions\n", "\n", "Now we'll define our training and evaluation functions. These functions handle:\n", "- **Forward pass**: Data → Model → Predictions\n", "- **Backward pass**: Calculate gradients and update weights\n", "- **Evaluation**: Track performance on test data" ] }, { "cell_type": "code", "execution_count": null, "id": "afe", "metadata": {}, "outputs": [ { "name": "stdout", "output_type": "stream", "text": [ " Training and evaluation functions defined!\n" ] } ], "source": [ "# Define training and evaluation functions\n", "from tqdm import tqdm\n", "\n", "def train_epoch(model, dataloader, optimizer, scheduler, device):\n", " \"\"\"\n", " Train the model for one complete epoch\n", " \n", " Returns:\n", " avg_loss (float): Average training loss\n", " accuracy (float): Training accuracy\n", " \"\"\"\n", " model.train() # Set model to training mode (enables dropout, etc.)\n", " total_loss = \n", " correct_predictions = \n", " total_predictions = \n", " \n", " # Progress bar for visual feedback\n", " progress_bar = tqdm(dataloader, desc=' Training')\n", " \n", " for batch in progress_bar:\n", " # Move batch data to device (GPU/CPU)\n", " input_ids = batch['input_ids'].to(device)\n", " attention_mask = batch['attention_mask'].to(device)\n", " labels = batch['labels'].to(device)\n", " \n", " # Reset gradients from previous iteration\n", " optimizer.zero_grad()\n", " \n", " # Forward pass: input → model → predictions\n", " outputs = model(\n", " input_ids=input_ids,\n", " attention_mask=attention_mask,\n", " labels=labels\n", " )\n", " \n", " loss = outputs.loss # Cross-entropy loss\n", " logits = outputs.logits # Raw prediction scores\n", " \n", " # Backward pass: calculate gradients\n", " loss.backward()\n", " \n", " # Update model weights\n", " optimizer.step()\n", " scheduler.step() # Update learning rate\n", " \n", " # Track performance metrics\n", " total_loss += loss.item()\n", " predictions = torch.argmax(logits, dim=) # Convert scores to predictions\n", " correct_predictions += (predictions == labels).sum().item()\n", " total_predictions += labels.size()\n", " \n", " # Update progress bar with current metrics\n", " progress_bar.set_postfix({\n", " 'loss': f'{loss.item():.f}',\n", " 'acc': f'{correct_predictions/total_predictions:.f}'\n", " })\n", " \n", " # Calculate averages\n", " avg_loss = total_loss / len(dataloader)\n", " accuracy = correct_predictions / total_predictions\n", " \n", " return avg_loss, accuracy\n", "\n", "\n", "def evaluate(model, dataloader, device):\n", " \"\"\"\n", " Evaluate model performance on test/validation data\n", " \n", " Returns:\n", " avg_loss (float): Average evaluation loss\n", " accuracy (float): Evaluation accuracy\n", " \"\"\"\n", " model.eval() # Set model to evaluation mode (disables dropout, etc.)\n", " total_loss = \n", " correct_predictions = \n", " total_predictions = \n", " \n", " # Disable gradient computation for faster inference\n", " with torch.no_grad():\n", " for batch in tqdm(dataloader, desc=' Evaluating'):\n", " # Move batch data to device\n", " input_ids = batch['input_ids'].to(device)\n", " attention_mask = batch['attention_mask'].to(device)\n", " labels = batch['labels'].to(device)\n", " \n", " # Forward pass only (no backpropagation)\n", " outputs = model(\n", " input_ids=input_ids,\n", " attention_mask=attention_mask,\n", " labels=labels\n", " )\n", " \n", " loss = outputs.loss\n", " logits = outputs.logits\n", " \n", " # Track metrics\n", " total_loss += loss.item()\n", " predictions = torch.argmax(logits, dim=)\n", " correct_predictions += (predictions == labels).sum().item()\n", " total_predictions += labels.size()\n", " \n", " # Calculate averages\n", " avg_loss = total_loss / len(dataloader)\n", " accuracy = correct_predictions / total_predictions\n", " \n", " return avg_loss, accuracy\n", "\n", "print(\" Training and evaluation functions defined!\")\n", "print(\"\\n Function overview:\")\n", "print(\" • train_epoch(): Trains model for one epoch, updates weights\")\n", "print(\" • evaluate(): Tests model performance without updating weights\")\n", "print(\" • Both functions track loss and accuracy metrics\")\n", "print(\" • Progress bars show real-time training/evaluation progress\")" ] }, { "cell_type": "markdown", "id": "ecbf", "metadata": {}, "source": [ "## Step : BERT Fine-tuning Training Loop\n", "\n", "This is where the magic happens! We'll train our BERT model for epochs and watch it learn to understand movie review sentiments.\n", "\n", "**What to expect:**\n", "- **Epoch **: ~-% accuracy (rapid initial learning)\n", "- **Epoch **: ~-% accuracy (fine-tuning improvements)\n", "- **Epoch **: ~-% accuracy (convergence)\n", "\n", "**Training time estimates:**\n", "- With GPU: ~- minutes total\n", "- With CPU: ~- hours total" ] }, { "cell_type": "code", "execution_count": null, "id": "fc", "metadata": {}, "outputs": [ { "name": "stdout", "output_type": "stream", "text": [ "============================================================\n", " STARTING BERT FINE-TUNING\n", "============================================================\n", "Device: cuda\n", "Epochs: \n", "Batch size: \n", "Learning rate: e-\n", "Total parameters: ,,\n", "============================================================\n", "\n", " EPOCH /\n", "------------------------------------------------------------\n" ] }, { "name": "stderr", "output_type": "stream", "text": [ "Training: %|██████████| / [:<:, .it/s, loss=., acc=.]\n", "Evaluating: %|██████████| / [:<:, .it/s]\n" ] }, { "name": "stdout", "output_type": "stream", "text": [ "\n", " Results:\n", " Train Loss: . | Train Acc: . (.%)\n", " Test Loss: . | Test Acc: . (.%)\n", " New best accuracy: .\n", "------------------------------------------------------------\n", "\n", " EPOCH /\n", "------------------------------------------------------------\n" ] }, { "name": "stderr", "output_type": "stream", "text": [ "Training: %|██████████| / [:<:, .it/s, loss=., acc=.] \n", "Evaluating: %|██████████| / [:<:, .it/s]\n" ] }, { "name": "stdout", "output_type": "stream", "text": [ "\n", " Results:\n", " Train Loss: . | Train Acc: . (.%)\n", " Test Loss: . | Test Acc: . (.%)\n", "------------------------------------------------------------\n", "\n", " EPOCH /\n", "------------------------------------------------------------\n" ] }, { "name": "stderr", "output_type": "stream", "text": [ "Training: %|██████████| / [::<:, .s/it, loss=., acc=.] \n", "Evaluating: %|██████████| / [:<:, .it/s]" ] }, { "name": "stdout", "output_type": "stream", "text": [ "\n", " Results:\n", " Train Loss: . | Train Acc: . (.%)\n", " Test Loss: . | Test Acc: . (.%)\n", " New best accuracy: .\n", "------------------------------------------------------------\n", "\n", "============================================================\n", " TRAINING COMPLETE!\n", " Best Test Accuracy: . (.%)\n", " Improvement over baseline: .%\n", "============================================================\n" ] }, { "name": "stderr", "output_type": "stream", "text": [ "\n" ] } ], "source": [ "# MAIN TRAINING LOOP - FINE-TUNE BERT FOR SENTIMENT ANALYSIS! \n", "\n", "print(\"=\"*)\n", "print(\" BERT FINE-TUNING TRAINING STARTED\")\n", "print(\"=\"*)\n", "print(f\" Device: {device}\")\n", "print(f\" Epochs: {epochs}\")\n", "print(f\" Batch size: reviews per batch\")\n", "print(f\" Learning rate: e-\")\n", "print(f\" Total parameters: {model.num_parameters():,}\")\n", "print(f\" Target: Beat baseline accuracy of ~.%\")\n", "print(\"=\"*)\n", "\n", "# Track the best performance\n", "best_accuracy = \n", "training_history = []\n", "\n", "# Training loop: repeat for specified number of epochs\n", "for epoch in range(epochs):\n", " print(f\"\\n EPOCH {epoch + }/{epochs}\")\n", " print(\"-\"*)\n", " \n", " # Train for one epoch\n", " print(\" Training phase...\")\n", " train_loss, train_acc = train_epoch(model, train_loader, optimizer, scheduler, device)\n", " \n", " # Evaluate on test set\n", " print(\" Evaluation phase...\")\n", " test_loss, test_acc = evaluate(model, test_loader, device)\n", " \n", " # Store results\n", " training_history.append({\n", " 'epoch': epoch + ,\n", " 'train_loss': train_loss,\n", " 'train_acc': train_acc,\n", " 'test_loss': test_loss,\n", " 'test_acc': test_acc\n", " })\n", " \n", " # Display results for this epoch\n", " print(f\"\\n EPOCH {epoch + } RESULTS:\")\n", " print(f\" Training → Loss: {train_loss:.f} | Accuracy: {train_acc:.f} ({train_acc*:.f}%)\")\n", " print(f\" Test → Loss: {test_loss:.f} | Accuracy: {test_acc:.f} ({test_acc*:.f}%)\")\n", " \n", " # Check for improvement\n", " if test_acc > best_accuracy:\n", " best_accuracy = test_acc\n", " improvement = \" NEW BEST!\" if epoch > else \" BASELINE SET\"\n", " print(f\" {improvement} Best accuracy: {best_accuracy:.f} ({best_accuracy*:.f}%)\")\n", " else:\n", " print(f\" Best so far: {best_accuracy:.f} ({best_accuracy*:.f}%)\")\n", " \n", " print(\"-\"*)\n", "\n", "# Final summary\n", "baseline_accuracy = . # From our logistic regression baseline\n", "improvement = (best_accuracy - baseline_accuracy) * \n", "\n", "print(f\"\\n{'='*}\")\n", "print(\" TRAINING COMPLETED! \")\n", "print(\"=\"*)\n", "print(f\" Best BERT accuracy: {best_accuracy:.f} ({best_accuracy*:.f}%)\")\n", "print(f\" Baseline accuracy: {baseline_accuracy:.f} ({baseline_accuracy*:.f}%)\")\n", "print(f\" Improvement: {improvement:+.f} percentage points\")\n", "print(f\" Relative improvement: {(improvement/baseline_accuracy)*:+.f}%\")\n", "print(\"=\"*)\n", "\n", "# Performance interpretation\n", "if best_accuracy > .:\n", " print(\" EXCELLENT! Your BERT model achieved outstanding performance!\")\n", "elif best_accuracy > .:\n", " print(\" GREAT! Your BERT model shows significant improvement over baseline!\")\n", "elif best_accuracy > baseline_accuracy:\n", " print(\" GOOD! BERT outperformed the baseline, which is expected!\")\n", "else:\n", " print(\" Hmm, something might be off. BERT should typically beat the baseline.\")\n", "\n", "print(f\"\\n Key takeaways:\")\n", "print(f\" • BERT's bidirectional context understanding → Better sentiment analysis\")\n", "print(f\" • Transfer learning from pre-trained knowledge → Faster convergence\") \n", "print(f\" • Fine-tuning approach → Domain-specific adaptation\")" ] }, { "cell_type": "markdown", "id": "bf", "metadata": {}, "source": [ "## Congratulations! \n", "\n", "You've successfully fine-tuned BERT for sentiment analysis! \n", "\n", "### **What You've Learned:**\n", "\n", ". **Traditional ML vs Deep Learning**: Saw the performance difference between TF-IDF + Logistic Regression vs BERT\n", ". **Transfer Learning**: Leveraged pre-trained BERT knowledge for your specific task\n", ". **Fine-tuning Process**: Understood how to adapt pre-trained models to new domains\n", ". **PyTorch Training Loop**: Implemented a complete training pipeline with proper evaluation\n", "\n", "### **Next Steps:**\n", "\n", "- **Try different models**: experiment with RoBERTa, DistilBERT, or domain-specific models\n", "- **Hyperparameter tuning**: adjust learning rates, batch sizes, or training epochs\n", "- **Real-world deployment**: integrate your model into a web application or API\n", "- **Advanced techniques**: implement techniques like gradient accumulation or mixed precision training\n", "\n", "### **Key Concepts Mastered:**\n", "\n", "- **Tokenization**: Converting text to model-readable format\n", "- **Attention mechanisms**: How BERT understands context\n", "- **Fine-tuning**: Adapting pre-trained models\n", "- **Evaluation metrics**: Tracking model performance\n", "\n", "Great job on completing this comprehensive BERT fine-tuning project! " ] } ], "metadata": { "kernelspec": { "display_name": "venv", "language": "python", "name": "python" }, "language_info": { "codemirror_mode": { "name": "ipython", "version": }, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython", "version": ".." } }, "nbformat": , "nbformat_minor": }